# Bandits_project
Implementation of variations of Multi-Armed Bandits algorithm.

Multi-armed bandits are a statistical machine learning tool. They involve trying various options by optimizing between greedy behaviour of
choosing what seems to be the best option and exploring other options. The jupyter notebook here is an implementation of various variations
of the multi-armed bandits algorithm as specified in the PDF. 

We implemented some bandit algorithms as per this paper:
"Lihong Li, Wei Chu, John Langford, Robert E. Schapire, `A Contextual-Bandit Approach to Per-sonalized News Article Recommendation', in Proceedings of the Nineteenth International Conference
on World Wide Web (WWW 2010), Raleigh, NC, USA, 2010." 
The paper can be found on arvix: https://arxiv.org/pdf/1003.0146.pdf
